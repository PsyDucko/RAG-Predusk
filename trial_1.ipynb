{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc1f3066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in .\\venv\\Lib\\site-packages (5.2.2)\n",
      "Requirement already satisfied: chromadb in .\\venv\\Lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: pdfplumber in .\\venv\\Lib\\site-packages (0.11.9)\n",
      "Requirement already satisfied: pypdf in .\\venv\\Lib\\site-packages (6.6.2)\n",
      "Requirement already satisfied: pandas in .\\venv\\Lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in .\\venv\\Lib\\site-packages (2.4.2)\n",
      "Requirement already satisfied: torch in .\\venv\\Lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: transformers in .\\venv\\Lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: accelerate in .\\venv\\Lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: bitsandbytes in .\\venv\\Lib\\site-packages (0.49.1)\n",
      "Requirement already satisfied: pillow in .\\venv\\Lib\\site-packages (12.1.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in .\\venv\\Lib\\site-packages (from sentence-transformers) (1.3.7)\n",
      "Requirement already satisfied: scikit-learn in .\\venv\\Lib\\site-packages (from sentence-transformers) (1.8.0)\n",
      "Requirement already satisfied: scipy in .\\venv\\Lib\\site-packages (from sentence-transformers) (1.17.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in .\\venv\\Lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: tqdm in .\\venv\\Lib\\site-packages (from sentence-transformers) (4.67.2)\n",
      "Requirement already satisfied: filelock in .\\venv\\Lib\\site-packages (from transformers) (3.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in .\\venv\\Lib\\site-packages (from transformers) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in .\\venv\\Lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in .\\venv\\Lib\\site-packages (from transformers) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in .\\venv\\Lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in .\\venv\\Lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in .\\venv\\Lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in .\\venv\\Lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2026.1.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in .\\venv\\Lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in .\\venv\\Lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in .\\venv\\Lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.5.4)\n",
      "Requirement already satisfied: anyio in .\\venv\\Lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (4.12.1)\n",
      "Requirement already satisfied: certifi in .\\venv\\Lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in .\\venv\\Lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in .\\venv\\Lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in .\\venv\\Lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (0.16.0)\n",
      "Requirement already satisfied: build>=1.0.3 in .\\venv\\Lib\\site-packages (from chromadb) (1.4.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in .\\venv\\Lib\\site-packages (from chromadb) (2.12.5)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in .\\venv\\Lib\\site-packages (from chromadb) (1.4.3)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in .\\venv\\Lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.40.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in .\\venv\\Lib\\site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in .\\venv\\Lib\\site-packages (from chromadb) (1.23.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in .\\venv\\Lib\\site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in .\\venv\\Lib\\site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in .\\venv\\Lib\\site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in .\\venv\\Lib\\site-packages (from chromadb) (0.51.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in .\\venv\\Lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in .\\venv\\Lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in .\\venv\\Lib\\site-packages (from chromadb) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in .\\venv\\Lib\\site-packages (from chromadb) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in .\\venv\\Lib\\site-packages (from chromadb) (0.21.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in .\\venv\\Lib\\site-packages (from chromadb) (35.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in .\\venv\\Lib\\site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in .\\venv\\Lib\\site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in .\\venv\\Lib\\site-packages (from chromadb) (3.11.7)\n",
      "Requirement already satisfied: rich>=10.11.0 in .\\venv\\Lib\\site-packages (from chromadb) (14.3.2)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in .\\venv\\Lib\\site-packages (from chromadb) (4.26.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in .\\venv\\Lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.32.5)\n",
      "Requirement already satisfied: six>=1.5 in .\\venv\\Lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in .\\venv\\Lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in .\\venv\\Lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in .\\venv\\Lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in .\\venv\\Lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\venv\\Lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2.6.3)\n",
      "Requirement already satisfied: pdfminer.six==20251230 in .\\venv\\Lib\\site-packages (from pdfplumber) (20251230)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in .\\venv\\Lib\\site-packages (from pdfplumber) (5.3.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in .\\venv\\Lib\\site-packages (from pdfminer.six==20251230->pdfplumber) (46.0.4)\n",
      "Requirement already satisfied: tzdata in .\\venv\\Lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in .\\venv\\Lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in .\\venv\\Lib\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in .\\venv\\Lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: psutil in .\\venv\\Lib\\site-packages (from accelerate) (7.2.2)\n",
      "Requirement already satisfied: pyproject_hooks in .\\venv\\Lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in .\\venv\\Lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: cffi>=2.0.0 in .\\venv\\Lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.0.0)\n",
      "Requirement already satisfied: pycparser in .\\venv\\Lib\\site-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (3.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in .\\venv\\Lib\\site-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in .\\venv\\Lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in .\\venv\\Lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in .\\venv\\Lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in .\\venv\\Lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in .\\venv\\Lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in .\\venv\\Lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: coloredlogs in .\\venv\\Lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in .\\venv\\Lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.12.19)\n",
      "Requirement already satisfied: protobuf in .\\venv\\Lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in .\\venv\\Lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.1)\n",
      "Requirement already satisfied: zipp>=3.20 in .\\venv\\Lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in .\\venv\\Lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in .\\venv\\Lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in .\\venv\\Lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in .\\venv\\Lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.60b1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\venv\\Lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in .\\venv\\Lib\\site-packages (from pydantic>=1.9->chromadb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in .\\venv\\Lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in .\\venv\\Lib\\site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in .\\venv\\Lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in .\\venv\\Lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in .\\venv\\Lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in .\\venv\\Lib\\site-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
      "Requirement already satisfied: httptools>=0.6.3 in .\\venv\\Lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in .\\venv\\Lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in .\\venv\\Lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in .\\venv\\Lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (16.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in .\\venv\\Lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in .\\venv\\Lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in .\\venv\\Lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in .\\venv\\Lib\\site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: joblib>=1.3.0 in .\\venv\\Lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in .\\venv\\Lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install sentence-transformers chromadb pdfplumber pypdf pandas numpy \\\n",
    "    torch transformers accelerate bitsandbytes pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21032581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n",
      "‚úÖ Device: CPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PDF processing\n",
    "import pdfplumber\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# Vector store\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"‚úÖ Device: {'GPU (CUDA)' if torch.cuda.is_available() else 'CPU'}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b8308e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading free embedding model...\n",
      "(First run will download the model - about 90MB)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [00:00<00:00, 919.24it/s, Materializing param=pooler.dense.weight]                              \n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embedding model loaded successfully!\n",
      "   Model: all-MiniLM-L6-v2\n",
      "   Embedding dimension: 384\n",
      "   Max sequence length: 256\n",
      "\n",
      "üí° This model runs 100% locally - no internet or API needed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading free embedding model...\")\n",
    "print(\"(First run will download the model - about 90MB)\\n\")\n",
    "\n",
    "# Choose your embedding model:\n",
    "# 'all-MiniLM-L6-v2' - Fast, small (80MB), good quality\n",
    "# 'all-mpnet-base-v2' - Better quality, slightly larger (420MB)\n",
    "# 'paraphrase-multilingual-MiniLM-L12-v2' - Multilingual support\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"‚úÖ Embedding model loaded successfully!\")\n",
    "print(f\"   Model: all-MiniLM-L6-v2\")\n",
    "print(f\"   Embedding dimension: {embedding_model.get_sentence_embedding_dimension()}\")\n",
    "print(f\"   Max sequence length: {embedding_model.max_seq_length}\")\n",
    "print(\"\\nüí° This model runs 100% locally - no internet or API needed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da06b9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing embeddings...\n",
      "\n",
      "Generated 3 embeddings\n",
      "Embedding shape: (384,)\n",
      "\n",
      "Similarity scores:\n",
      "  Sentence 1 vs 2 (both about AI): 0.403\n",
      "  Sentence 1 vs 3 (different topics): 0.071\n",
      "\n",
      "‚úÖ Embeddings working correctly!\n"
     ]
    }
   ],
   "source": [
    "# Quick test\n",
    "test_sentences = [\n",
    "    \"Machine learning is a subset of artificial intelligence\",\n",
    "    \"Deep learning uses neural networks with multiple layers\",\n",
    "    \"I love eating pizza for dinner\"\n",
    "]\n",
    "\n",
    "print(\"Testing embeddings...\\n\")\n",
    "embeddings = embedding_model.encode(test_sentences)\n",
    "\n",
    "print(f\"Generated {len(embeddings)} embeddings\")\n",
    "print(f\"Embedding shape: {embeddings[0].shape}\")\n",
    "\n",
    "# Calculate similarity\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "print(\"\\nSimilarity scores:\")\n",
    "print(f\"  Sentence 1 vs 2 (both about AI): {cosine_similarity(embeddings[0], embeddings[1]):.3f}\")\n",
    "print(f\"  Sentence 1 vs 3 (different topics): {cosine_similarity(embeddings[0], embeddings[2]):.3f}\")\n",
    "print(\"\\n‚úÖ Embeddings working correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd7b5ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PDF Extractor ready\n"
     ]
    }
   ],
   "source": [
    "class PDFContentExtractor:\n",
    "    \"\"\"\n",
    "    Extract text and tables from PDFs - completely free!\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pdf_path: str):\n",
    "        self.pdf_path = pdf_path\n",
    "        self.pages_content = []\n",
    "        self.extracted_tables = []\n",
    "    \n",
    "    def extract_all(self) -> Dict:\n",
    "        \"\"\"Extract all content from PDF\"\"\"\n",
    "        print(f\"\\nüìÑ Processing: {Path(self.pdf_path).name}\")\n",
    "        \n",
    "        with pdfplumber.open(self.pdf_path) as pdf:\n",
    "            total_pages = len(pdf.pages)\n",
    "            \n",
    "            for page_num, page in enumerate(pdf.pages, 1):\n",
    "                print(f\"   Processing page {page_num}/{total_pages}...\", end='\\r')\n",
    "                \n",
    "                page_data = {\n",
    "                    'page_number': page_num,\n",
    "                    'text': '',\n",
    "                    'tables': []\n",
    "                }\n",
    "                \n",
    "                # Extract text\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    page_data['text'] = text.strip()\n",
    "                \n",
    "                # Extract tables\n",
    "                tables = page.extract_tables()\n",
    "                for table_idx, table in enumerate(tables):\n",
    "                    if table and len(table) > 0:\n",
    "                        table_text = self._format_table(table, page_num, table_idx)\n",
    "                        page_data['tables'].append(table_text)\n",
    "                        self.extracted_tables.append({\n",
    "                            'page': page_num,\n",
    "                            'index': table_idx,\n",
    "                            'text': table_text\n",
    "                        })\n",
    "                \n",
    "                self.pages_content.append(page_data)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Extracted: {len(self.pages_content)} pages, {len(self.extracted_tables)} tables\")\n",
    "        return self._compile_results()\n",
    "    \n",
    "    def _format_table(self, table: List[List], page_num: int, table_idx: int) -> str:\n",
    "        \"\"\"Convert table to readable text\"\"\"\n",
    "        lines = [f\"\\n[Table {table_idx + 1} on Page {page_num}]\"]\n",
    "        \n",
    "        for row in table:\n",
    "            cleaned_row = [str(cell).strip() if cell else \"\" for cell in row]\n",
    "            lines.append(\" | \".join(cleaned_row))\n",
    "        \n",
    "        return \"\\n\".join(lines)\n",
    "    \n",
    "    def _compile_results(self) -> Dict:\n",
    "        return {\n",
    "            'pages': self.pages_content,\n",
    "            'total_pages': len(self.pages_content),\n",
    "            'total_tables': len(self.extracted_tables)\n",
    "        }\n",
    "    \n",
    "    def create_documents(self) -> List[Dict]:\n",
    "        \"\"\"Create document chunks\"\"\"\n",
    "        documents = []\n",
    "        \n",
    "        for page_data in self.pages_content:\n",
    "            content_parts = []\n",
    "            \n",
    "            if page_data['text']:\n",
    "                content_parts.append(page_data['text'])\n",
    "            \n",
    "            if page_data['tables']:\n",
    "                content_parts.extend(page_data['tables'])\n",
    "            \n",
    "            if content_parts:\n",
    "                documents.append({\n",
    "                    'content': \"\\n\\n\".join(content_parts),\n",
    "                    'metadata': {\n",
    "                        'source': self.pdf_path,\n",
    "                        'page': page_data['page_number'],\n",
    "                        'has_tables': len(page_data['tables']) > 0\n",
    "                    }\n",
    "                })\n",
    "        \n",
    "        return documents\n",
    "\n",
    "print(\"‚úÖ PDF Extractor ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1d63436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROCESSING PDF FILES\n",
      "================================================================================\n",
      "\n",
      "üìÑ Processing: Paradigms_of_Programming.pdf\n",
      "   Processing page 46/46...\n",
      "‚úÖ Extracted: 46 pages, 46 tables\n",
      "   ‚úÖ Created 46 document chunks\n",
      "\n",
      "\n",
      "üìÑ Processing: barry.pdf\n",
      "   Processing page 210/210...\n",
      "‚úÖ Extracted: 210 pages, 0 tables\n",
      "   ‚úÖ Created 210 document chunks\n",
      "\n",
      "================================================================================\n",
      "üìä TOTAL DOCUMENTS: 256\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# ADD YOUR PDF FILES HERE\n",
    "# ============================================\n",
    "\n",
    "pdf_files = [\n",
    "    r'C:\\Users\\ASUS\\OneDrive\\Desktop\\RAG\\pdfs\\Paradigms_of_Programming.pdf',\n",
    "    r'C:\\Users\\ASUS\\OneDrive\\Desktop\\RAG\\pdfs\\barry.pdf',\n",
    "\n",
    "]\n",
    "\n",
    "# ============================================\n",
    "\n",
    "all_documents = []\n",
    "\n",
    "if pdf_files:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PROCESSING PDF FILES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for pdf_path in pdf_files:\n",
    "        if not os.path.exists(pdf_path):\n",
    "            print(f\"\\n‚ö†Ô∏è  File not found: {pdf_path}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            extractor = PDFContentExtractor(pdf_path)\n",
    "            results = extractor.extract_all()\n",
    "            docs = extractor.create_documents()\n",
    "            all_documents.extend(docs)\n",
    "            print(f\"   ‚úÖ Created {len(docs)} document chunks\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n   ‚ùå Error processing {pdf_path}: {e}\\n\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚ö†Ô∏è  NO PDF FILES SPECIFIED - Using Sample Documents\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nTo use your own PDFs, add file paths to the 'pdf_files' list above.\")\n",
    "    print(\"Example: pdf_files = ['/path/to/your/document.pdf']\\n\")\n",
    "    \n",
    "    # Sample documents for testing\n",
    "    sample_texts = [\n",
    "        \"\"\"Machine Learning is a branch of artificial intelligence that focuses on building systems \n",
    "        that can learn from data. It includes various approaches such as supervised learning, where \n",
    "        models learn from labeled data, unsupervised learning, where patterns are discovered in \n",
    "        unlabeled data, and reinforcement learning, where agents learn through interaction with \n",
    "        an environment.\"\"\",\n",
    "        \n",
    "        \"\"\"Deep Learning is a subset of machine learning that uses artificial neural networks with \n",
    "        multiple layers. These deep neural networks can automatically learn hierarchical \n",
    "        representations of data. Deep learning has achieved breakthrough results in computer vision, \n",
    "        natural language processing, and speech recognition tasks.\"\"\",\n",
    "        \n",
    "        \"\"\"Natural Language Processing (NLP) is a field of AI that focuses on enabling computers to \n",
    "        understand, interpret, and generate human language. Modern NLP uses transformer models like \n",
    "        BERT, GPT, and T5 for tasks such as text classification, machine translation, question \n",
    "        answering, and text generation.\"\"\",\n",
    "        \n",
    "        \"\"\"Computer Vision enables machines to interpret and understand visual information from the \n",
    "        world. Applications include image classification, object detection, semantic segmentation, \n",
    "        and facial recognition. Convolutional Neural Networks (CNNs) are the primary architecture \n",
    "        used in computer vision tasks.\"\"\",\n",
    "        \n",
    "        \"\"\"Reinforcement Learning (RL) is a machine learning paradigm where an agent learns to make \n",
    "        decisions by interacting with an environment. The agent receives rewards or penalties based \n",
    "        on its actions and learns to maximize cumulative reward. RL has been successfully applied \n",
    "        in game playing, robotics, and autonomous systems.\"\"\",\n",
    "    ]\n",
    "    \n",
    "    all_documents = [\n",
    "        {\n",
    "            'content': text,\n",
    "            'metadata': {'source': 'sample', 'page': i, 'has_tables': False}\n",
    "        }\n",
    "        for i, text in enumerate(sample_texts, 1)\n",
    "    ]\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(all_documents)} sample documents\\n\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"üìä TOTAL DOCUMENTS: {len(all_documents)}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b5f6d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chunking documents...\n",
      "‚úÖ Created 468 chunks from 256 documents\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(text: str, chunk_size: int = 1000, overlap: int = 200) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split text into overlapping chunks\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = ' '.join(words[i:i + chunk_size])\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "    \n",
    "    return chunks if chunks else [text]\n",
    "\n",
    "# Chunk all documents\n",
    "print(\"\\nChunking documents...\")\n",
    "\n",
    "chunked_documents = []\n",
    "for doc in all_documents:\n",
    "    chunks = chunk_text(doc['content'], chunk_size=500, overlap=100)\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        chunked_documents.append({\n",
    "            'content': chunk,\n",
    "            'metadata': doc['metadata']\n",
    "        })\n",
    "\n",
    "print(f\"‚úÖ Created {len(chunked_documents)} chunks from {len(all_documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc1e2ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CREATING VECTOR STORE\n",
      "================================================================================\n",
      "\n",
      "Generating embeddings for all documents...\n",
      "(This may take a minute for large documents)\n",
      "\n",
      "   Encoding 468 text chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:13<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   Adding to vector store...\n",
      "\n",
      "================================================================================\n",
      "‚úÖ VECTOR STORE CREATED!\n",
      "   Location: ./chroma_free_db\n",
      "   Documents: 468\n",
      "   Embedding dimension: 384\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VECTOR STORE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nGenerating embeddings for all documents...\")\n",
    "print(\"(This may take a minute for large documents)\\n\")\n",
    "\n",
    "# Initialize ChromaDB\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_free_db\")\n",
    "\n",
    "# Delete existing collection if it exists\n",
    "try:\n",
    "    chroma_client.delete_collection(name=\"free_rag_collection\")\n",
    "    print(\"   Cleared existing collection\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create new collection\n",
    "collection = chroma_client.create_collection(\n",
    "    name=\"free_rag_collection\",\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ")\n",
    "\n",
    "# Extract data\n",
    "texts = [doc['content'] for doc in chunked_documents]\n",
    "metadatas = [doc['metadata'] for doc in chunked_documents]\n",
    "ids = [f\"doc_{i}\" for i in range(len(chunked_documents))]\n",
    "\n",
    "# Generate embeddings (FREE - runs locally)\n",
    "print(f\"   Encoding {len(texts)} text chunks...\")\n",
    "embeddings = embedding_model.encode(\n",
    "    texts,\n",
    "    show_progress_bar=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Add to ChromaDB\n",
    "print(\"\\n   Adding to vector store...\")\n",
    "collection.add(\n",
    "    embeddings=embeddings.tolist(),\n",
    "    documents=texts,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"‚úÖ VECTOR STORE CREATED!\")\n",
    "print(f\"   Location: ./chroma_free_db\")\n",
    "print(f\"   Documents: {len(texts)}\")\n",
    "print(f\"   Embedding dimension: {embeddings.shape[1]}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b619263b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MMR retrieval function ready\n"
     ]
    }
   ],
   "source": [
    "def mmr_retrieval(query: str, k: int = 5, lambda_param: float = 0.5, fetch_k: int = 20):\n",
    "    \"\"\"\n",
    "    Maximal Marginal Relevance retrieval for diverse results\n",
    "    \n",
    "    Args:\n",
    "        query: Search query\n",
    "        k: Number of documents to return\n",
    "        lambda_param: Balance between relevance (1.0) and diversity (0.0)\n",
    "        fetch_k: Initial candidates to fetch before MMR reranking\n",
    "    \"\"\"\n",
    "    # Encode query\n",
    "    query_embedding = embedding_model.encode(query)\n",
    "    \n",
    "    # Get initial candidates\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding.tolist()],\n",
    "        n_results=min(fetch_k, collection.count()),\n",
    "        include=['embeddings', 'documents', 'metadatas', 'distances']\n",
    "    )\n",
    "    \n",
    "    if not results['documents'][0]:\n",
    "        return []\n",
    "    \n",
    "    # Extract data\n",
    "    candidate_docs = results['documents'][0]\n",
    "    candidate_embeddings = np.array(results['embeddings'][0])\n",
    "    candidate_metadatas = results['metadatas'][0]\n",
    "    candidate_distances = results['distances'][0]\n",
    "    \n",
    "    # Convert distances to similarity scores (ChromaDB uses L2 distance)\n",
    "    # For cosine similarity from L2: similarity = 1 - (distance^2 / 2)\n",
    "    relevance_scores = [1 - (dist**2 / 2) for dist in candidate_distances]\n",
    "    \n",
    "    # MMR algorithm\n",
    "    selected_indices = []\n",
    "    selected_docs = []\n",
    "    \n",
    "    # Select first document (most relevant)\n",
    "    first_idx = np.argmax(relevance_scores)\n",
    "    selected_indices.append(first_idx)\n",
    "    selected_docs.append({\n",
    "        'content': candidate_docs[first_idx],\n",
    "        'metadata': candidate_metadatas[first_idx],\n",
    "        'relevance': relevance_scores[first_idx]\n",
    "    })\n",
    "    \n",
    "    # Select remaining documents\n",
    "    while len(selected_indices) < min(k, len(candidate_docs)):\n",
    "        mmr_scores = []\n",
    "        \n",
    "        for i in range(len(candidate_docs)):\n",
    "            if i in selected_indices:\n",
    "                mmr_scores.append(-float('inf'))\n",
    "                continue\n",
    "            \n",
    "            # Calculate MMR score\n",
    "            relevance = relevance_scores[i]\n",
    "            \n",
    "            # Max similarity to already selected documents\n",
    "            similarities = [\n",
    "                np.dot(candidate_embeddings[i], candidate_embeddings[j]) / \n",
    "                (np.linalg.norm(candidate_embeddings[i]) * np.linalg.norm(candidate_embeddings[j]))\n",
    "                for j in selected_indices\n",
    "            ]\n",
    "            max_similarity = max(similarities)\n",
    "            \n",
    "            # MMR formula: Œª * Relevance - (1-Œª) * MaxSimilarity\n",
    "            mmr_score = lambda_param * relevance - (1 - lambda_param) * max_similarity\n",
    "            mmr_scores.append(mmr_score)\n",
    "        \n",
    "        # Select next document\n",
    "        next_idx = np.argmax(mmr_scores)\n",
    "        selected_indices.append(next_idx)\n",
    "        selected_docs.append({\n",
    "            'content': candidate_docs[next_idx],\n",
    "            'metadata': candidate_metadatas[next_idx],\n",
    "            'relevance': relevance_scores[next_idx],\n",
    "            'mmr_score': mmr_scores[next_idx]\n",
    "        })\n",
    "    \n",
    "    return selected_docs\n",
    "\n",
    "print(\"‚úÖ MMR retrieval function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04837409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LOADING FREE LOCAL LLM\n",
      "================================================================================\n",
      "\n",
      "üîÑ Loading model... (First time will download ~2-4GB)\n",
      "   This may take a few minutes on first run.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 201/201 [00:02<00:00, 68.66it/s, Materializing param=model.norm.weight]                               \n",
      "Passing `generation_config` together with generation-related arguments=({'top_p', 'repetition_penalty', 'temperature', 'max_new_tokens', 'do_sample'}) is deprecated and will be removed in future versions. Please pass either a `generation_config` object OR all generation parameters explicitly, but not both.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "‚úÖ LOCAL LLM LOADED SUCCESSFULLY!\n",
      "   Model: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "   Device: CPU\n",
      "   Status: 100% Free, No API, Runs Offline\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING FREE LOCAL LLM\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nüîÑ Loading model... (First time will download ~2-4GB)\")\n",
    "print(\"   This may take a few minutes on first run.\\n\")\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# Using TinyLlama - small, fast, free\n",
    "# Alternative models:\n",
    "# - \"microsoft/phi-2\" (better quality, needs more RAM)\n",
    "# - \"stabilityai/stablelm-2-zephyr-1_6b\" (good balance)\n",
    "\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "        device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "    \n",
    "    # Create pipeline\n",
    "    llm_pipeline = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.1\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ LOCAL LLM LOADED SUCCESSFULLY!\")\n",
    "    print(f\"   Model: {model_name}\")\n",
    "    print(f\"   Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "    print(\"   Status: 100% Free, No API, Runs Offline\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    def generate_answer(prompt: str) -> str:\n",
    "        \"\"\"Generate answer using local LLM\"\"\"\n",
    "        response = llm_pipeline(prompt)\n",
    "        # Extract only the new generated text\n",
    "        full_text = response[0]['generated_text']\n",
    "        answer = full_text[len(prompt):].strip()\n",
    "        return answer\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error loading model: {e}\")\n",
    "    print(\"\\nüí° Alternative: Install Ollama for better local LLMs\")\n",
    "    print(\"   Visit: https://ollama.ai\")\n",
    "    \n",
    "    # Fallback: simple template-based response\n",
    "    def generate_answer(prompt: str) -> str:\n",
    "        return \"[Model not loaded. Please ensure you have enough RAM/GPU or use Ollama]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4bb31fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Query function ready!\n"
     ]
    }
   ],
   "source": [
    "def query_rag(\n",
    "    question: str,\n",
    "    k: int = 4,\n",
    "    lambda_param: float = 0.5,\n",
    "    show_sources: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Query the RAG system - 100% FREE!\n",
    "    \n",
    "    Args:\n",
    "        question: Your question\n",
    "        k: Number of relevant documents to retrieve\n",
    "        lambda_param: MMR diversity (0=max diversity, 1=max relevance)\n",
    "        show_sources: Whether to display source documents\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚ùì QUESTION\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{question}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Step 1: Retrieve relevant documents\n",
    "    print(\"\\nüîç Retrieving relevant documents using MMR...\")\n",
    "    retrieved_docs = mmr_retrieval(\n",
    "        query=question,\n",
    "        k=k,\n",
    "        lambda_param=lambda_param,\n",
    "        fetch_k=20\n",
    "    )\n",
    "    \n",
    "    if not retrieved_docs:\n",
    "        print(\"‚ùå No relevant documents found!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"‚úÖ Retrieved {len(retrieved_docs)} relevant documents\")\n",
    "    \n",
    "    # Step 2: Build context\n",
    "    context_parts = []\n",
    "    for i, doc in enumerate(retrieved_docs, 1):\n",
    "        source = doc['metadata'].get('source', 'Unknown')\n",
    "        page = doc['metadata'].get('page', '?')\n",
    "        context_parts.append(\n",
    "            f\"[Document {i} - Source: {Path(source).name}, Page: {page}]\\n{doc['content']}\"\n",
    "        )\n",
    "    \n",
    "    context = \"\\n\\n\" + \"-\"*80 + \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    # Step 3: Create prompt\n",
    "    prompt = f\"\"\"<|system|>\n",
    "You are a helpful AI assistant. Answer the question based on the provided context.\n",
    "If the answer is not in the context, say so. Be concise and accurate.\n",
    "</s>\n",
    "<|user|>\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "</s>\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "    \n",
    "    # Step 4: Generate answer\n",
    "    print(\"\\nü§ñ Generating answer...\\n\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"üí° ANSWER\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        answer = generate_answer(prompt)\n",
    "        print(answer)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating answer: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Step 5: Show sources\n",
    "    if show_sources:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üìö SOURCE DOCUMENTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for i, doc in enumerate(retrieved_docs, 1):\n",
    "            print(f\"\\n[Source {i}]\")\n",
    "            print(f\"  üìÑ File: {Path(doc['metadata']['source']).name}\")\n",
    "            print(f\"  üìë Page: {doc['metadata']['page']}\")\n",
    "            print(f\"  üéØ Relevance: {doc['relevance']:.3f}\")\n",
    "            print(f\"\\n  Content preview:\")\n",
    "            preview = doc['content'][:250].replace('\\n', ' ')\n",
    "            print(f\"  {preview}...\")\n",
    "            print(\"-\" * 80)\n",
    "\n",
    "print(\"‚úÖ Query function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddb9c1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=2048) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "‚ùì QUESTION\n",
      "================================================================================\n",
      "What did amy do?\n",
      "================================================================================\n",
      "\n",
      "üîç Retrieving relevant documents using MMR...\n",
      "‚úÖ Retrieved 3 relevant documents\n",
      "\n",
      "ü§ñ Generating answer...\n",
      "\n",
      "================================================================================\n",
      "üí° ANSWER\n",
      "================================================================================\n",
      "Amy did not know how to use a computer, which caused Tracy to lose her job as a computer expert at the prison. This led to her becoming a saleswoman in the children's department at Saks Fifth Avenue, where a hysterical customer recognized her as a murderess and discharged her immediately. The unfairness of what happened to her further contributed to her feelings of desperation and resulted in her losing everything she had worked for.\n",
      "\n",
      "================================================================================\n",
      "üìö SOURCE DOCUMENTS\n",
      "================================================================================\n",
      "\n",
      "[Source 1]\n",
      "  üìÑ File: barry.pdf\n",
      "  üìë Page: 46\n",
      "  üéØ Relevance: 0.876\n",
      "\n",
      "  Content preview:\n",
      "  the daytime she had the illusion of freedom. After breakfast in the prison kitchen, she walked over to the warden's cottage and made breakfast for Amy. Tracy had learned a good deal about cooking from Charles, and she was tempted by the varieties of ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Source 2]\n",
      "  üìÑ File: barry.pdf\n",
      "  üìë Page: 52\n",
      "  üéØ Relevance: 0.871\n",
      "\n",
      "  Content preview:\n",
      "  me to bring Amy back?\" \"Oh, about three o'clock. They should be gone by then.\" So would the truck. The world was tumbling in on her. \"I---\" Are you all right? You look pale.\" That was it. She would say she was ill. Go to the hospital. But then they w...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Source 3]\n",
      "  üìÑ File: barry.pdf\n",
      "  üìë Page: 79\n",
      "  üéØ Relevance: 0.804\n",
      "\n",
      "  Content preview:\n",
      "  79 When the First Hanover Bank of New York opened at 10:00 the following morning, Rita Gonzales was there to withdraw s8 the,money from her account. \"How much ees in it?\" she asked. The teller checked. \"Thirteen hundred eighty-five dollars and sixty-...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test with a sample question\n",
    "query_rag(\n",
    "    question=\"What did amy do?\",\n",
    "    k=3,\n",
    "    lambda_param=0.3,\n",
    "    show_sources=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "512deb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_mode():\n",
    "    \"\"\"\n",
    "    Interactive question-answering mode\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üöÄ INTERACTIVE RAG SYSTEM (100% Free!)\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nAsk questions about your documents!\")\n",
    "    print(\"Commands:\")\n",
    "    print(\"  - Type your question to get an answer\")\n",
    "    print(\"  - 'quit' or 'exit' to stop\")\n",
    "    print(\"  - 'settings' to adjust retrieval parameters\")\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    \n",
    "    k = 4\n",
    "    lambda_param = 0.5\n",
    "    \n",
    "    while True:\n",
    "        question = input(\"\\nüí¨ Your question: \").strip()\n",
    "        \n",
    "        if question.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"\\nüëã Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        if question.lower() == 'settings':\n",
    "            print(\"\\nCurrent settings:\")\n",
    "            print(f\"  k (documents to retrieve): {k}\")\n",
    "            print(f\"  lambda (diversity): {lambda_param}\")\n",
    "            \n",
    "            try:\n",
    "                new_k = input(\"\\nNew k value (press Enter to keep current): \").strip()\n",
    "                if new_k:\n",
    "                    k = int(new_k)\n",
    "                \n",
    "                new_lambda = input(\"New lambda value 0-1 (press Enter to keep current): \").strip()\n",
    "                if new_lambda:\n",
    "                    lambda_param = float(new_lambda)\n",
    "                \n",
    "                print(f\"\\n‚úÖ Settings updated: k={k}, lambda={lambda_param}\")\n",
    "            except:\n",
    "                print(\"‚ùå Invalid input. Settings unchanged.\")\n",
    "            continue\n",
    "        \n",
    "        if not question:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            query_rag(question, k=k, lambda_param=lambda_param, show_sources=True)\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error: {str(e)}\")\n",
    "            print(\"Please try rephrasing your question.\")\n",
    "\n",
    "# Uncomment to start interactive mode:\n",
    "# interactive_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9939f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üöÄ INTERACTIVE RAG SYSTEM (100% Free!)\n",
      "================================================================================\n",
      "\n",
      "Ask questions about your documents!\n",
      "Commands:\n",
      "  - Type your question to get an answer\n",
      "  - 'quit' or 'exit' to stop\n",
      "  - 'settings' to adjust retrieval parameters\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=2048) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "‚ùì QUESTION\n",
      "================================================================================\n",
      "who is author of the book\n",
      "================================================================================\n",
      "\n",
      "üîç Retrieving relevant documents using MMR...\n",
      "‚úÖ Retrieved 4 relevant documents\n",
      "\n",
      "ü§ñ Generating answer...\n",
      "\n",
      "================================================================================\n",
      "üí° ANSWER\n",
      "================================================================================\n",
      "The author of the book mentioned in the given context is Barry Michels.\n",
      "\n",
      "================================================================================\n",
      "üìö SOURCE DOCUMENTS\n",
      "================================================================================\n",
      "\n",
      "[Source 1]\n",
      "  üìÑ File: barry.pdf\n",
      "  üìë Page: 107\n",
      "  üéØ Relevance: 0.800\n",
      "\n",
      "  Content preview:\n",
      "  107 BOOK THREE Chapter 20 It's time to begin my new life, Tracy decided. But what kind of life? I've gone from an innocent, naive victim to a... what? A thief--- that's what. She thought of Joe Romano and Anthony Orsatti and Perry Pope and Judge Lawr...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Source 2]\n",
      "  üìÑ File: Paradigms_of_Programming.pdf\n",
      "  üìë Page: 2\n",
      "  üéØ Relevance: 0.742\n",
      "\n",
      "  Content preview:\n",
      "  GettingStarted Black-BoxAbstraction Foodforthought Must Read textbooks:- SICP (pdf available online) 2/28 [Table 1 on Page 2] GettingStarted Black-BoxAbstraction Foodforthought | Must Read textbooks:- SICP (pdf available online) 2/28 |...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Source 3]\n",
      "  üìÑ File: barry.pdf\n",
      "  üìë Page: 203\n",
      "  üéØ Relevance: 0.792\n",
      "\n",
      "  Content preview:\n",
      "  Lord's right arm, his scourge, punishing the wicked. ********** Daniel Cooper rose from his bath and prepared for bed. Tomorrow, he thought. Tomorrow will be the whore's day of retribution. He wished his mother could be there to see it. BOOK THREE Ch...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Source 4]\n",
      "  üìÑ File: barry.pdf\n",
      "  üìë Page: 64\n",
      "  üéØ Relevance: 0.726\n",
      "\n",
      "  Content preview:\n",
      "  Anthony Orsatti said, and he was out of the chair before the woman could close the door. He took his time reading the cable, then he focused his eyes on Joe Romano. In a voice so low that Romano could barely hear him, Anthony Orsatti said, \"I'll read...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üëã Goodbye!\n"
     ]
    }
   ],
   "source": [
    "interactive_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0aba1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üî¨ RETRIEVAL METHOD COMPARISON\n",
      "================================================================================\n",
      "Query: What was tracy upto?\n",
      "\n",
      "\n",
      "1Ô∏è‚É£ STANDARD SIMILARITY SEARCH\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[1] Similarity: 0.899\n",
      "    109 She had dinner in her cabin. As she ate, she wondered what ill fate had placed Jeff Stevens in her path again. She w...\n",
      "\n",
      "[2] Similarity: 0.892\n",
      "    looked at her in surprise. \"Come on. You mean you really don't know?\" \"Know what?\" \"Max Pierpont is one of the richest m...\n",
      "\n",
      "[3] Similarity: 0.880\n",
      "    89 Tracy felt her heart twisting in agony. She remembered the airport in New Orleans when they had handcuffed her, the s...\n",
      "\n",
      "[4] Similarity: 0.877\n",
      "    waited until dark before she set out. The parades had moved on to Chartres Street, and in the distance Tracy could hear ...\n",
      "\n",
      "\n",
      "2Ô∏è‚É£ MMR RETRIEVAL (Œª=0.5, Balanced)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[1] Relevance: 0.899\n",
      "    109 She had dinner in her cabin. As she ate, she wondered what ill fate had placed Jeff Stevens in her path again. She w...\n",
      "\n",
      "[2] Relevance: 0.857\n",
      "    up and scream, and she felt her nightgown and underpants being ripped away. Hands slid between her thighs, forcing her l...\n",
      "\n",
      "[3] Relevance: 0.864\n",
      "    129 disguises and accents. She acquired half a dozen passports. In various countries, she was a British duchess, a Frenc...\n",
      "\n",
      "[4] Relevance: 0.868\n",
      "    her baby. And yet, she thought, they won't let me keep it. They'll take it away from me because I'm going to be in priso...\n",
      "\n",
      "\n",
      "3Ô∏è‚É£ MMR RETRIEVAL (Œª=0.1, High Diversity)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[1] Relevance: 0.899\n",
      "    109 She had dinner in her cabin. As she ate, she wondered what ill fate had placed Jeff Stevens in her path again. She w...\n",
      "\n",
      "[2] Relevance: 0.857\n",
      "    up and scream, and she felt her nightgown and underpants being ripped away. Hands slid between her thighs, forcing her l...\n",
      "\n",
      "[3] Relevance: 0.864\n",
      "    129 disguises and accents. She acquired half a dozen passports. In various countries, she was a British duchess, a Frenc...\n",
      "\n",
      "[4] Relevance: 0.852\n",
      "    19 \"No,\" Tracy cried. \"No, please!\" She looked up at the judge. \"There's been a terrible mistake, Your Honor. I---\" And ...\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def compare_retrieval_methods(query: str, k: int = 5):\n",
    "    \"\"\"\n",
    "    Compare standard similarity search vs MMR retrieval\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üî¨ RETRIEVAL METHOD COMPARISON\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    \n",
    "    # Get query embedding\n",
    "    query_emb = embedding_model.encode(query)\n",
    "    \n",
    "    # Method 1: Standard similarity search\n",
    "    print(\"\\n1Ô∏è‚É£ STANDARD SIMILARITY SEARCH\")\n",
    "    print(\"-\" * 80)\n",
    "    standard_results = collection.query(\n",
    "        query_embeddings=[query_emb.tolist()],\n",
    "        n_results=k\n",
    "    )\n",
    "    \n",
    "    for i, (doc, dist) in enumerate(zip(standard_results['documents'][0], standard_results['distances'][0]), 1):\n",
    "        print(f\"\\n[{i}] Similarity: {1 - (dist**2/2):.3f}\")\n",
    "        print(f\"    {doc[:120]}...\")\n",
    "    \n",
    "    # Method 2: MMR (Balanced)\n",
    "    print(\"\\n\\n2Ô∏è‚É£ MMR RETRIEVAL (Œª=0.5, Balanced)\")\n",
    "    print(\"-\" * 80)\n",
    "    mmr_balanced = mmr_retrieval(query, k=k, lambda_param=0.5)\n",
    "    \n",
    "    for i, doc in enumerate(mmr_balanced, 1):\n",
    "        print(f\"\\n[{i}] Relevance: {doc['relevance']:.3f}\")\n",
    "        print(f\"    {doc['content'][:120]}...\")\n",
    "    \n",
    "    # Method 3: MMR (High Diversity)\n",
    "    print(\"\\n\\n3Ô∏è‚É£ MMR RETRIEVAL (Œª=0.1, High Diversity)\")\n",
    "    print(\"-\" * 80)\n",
    "    mmr_diverse = mmr_retrieval(query, k=k, lambda_param=0.1)\n",
    "    \n",
    "    for i, doc in enumerate(mmr_diverse, 1):\n",
    "        print(f\"\\n[{i}] Relevance: {doc['relevance']:.3f}\")\n",
    "        print(f\"    {doc['content'][:120]}...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Example:\n",
    "compare_retrieval_methods(\"What was tracy upto?\", k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db58468a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
